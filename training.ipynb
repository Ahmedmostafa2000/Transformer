{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Verbose\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "%xmode Verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(vocab_len, d_model):\n",
    "    j = np.arange(d_model)\n",
    "    Encodings = np.zeros((vocab_len, d_model))\n",
    "    for p in range(vocab_len):\n",
    "        Encodings[p][0::2] +=  np.sin(p/np.power(10000,2*j[0::2]/d_model))\n",
    "        Encodings[p][1::2] +=  np.cos(p/np.power(10000,2*j[0::2]/d_model))\n",
    "    return Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Uncomment to create padded sequence, it takes 12 mins\"\"\"\n",
    "\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "# df_train = pd.read_csv('D:/Industry/Projects/Datasets/cnn_dailymail/train.csv')\n",
    "# df_valid = pd.read_csv('D:/Industry/Projects/Datasets/cnn_dailymail/validation.csv')\n",
    "# df = pd.concat([df_train, df_valid]).reset_index()\n",
    "\n",
    "# import re\n",
    "# def remove_special_words(text):\n",
    "#     return re.sub(r'^@|^http|[^\\w\\s\\U0001F600-\\U0001F64F]','',text)\n",
    "\n",
    "# df[\"article\"] = df[\"article\"].apply(remove_special_words).str.lower()\n",
    "# df[\"highlights\"] = df[\"highlights\"].apply(remove_special_words).str.lower()\n",
    "# tokenizer_input = Tokenizer()\n",
    "# tokenizer_input.fit_on_texts(df['article'])\n",
    "# sequences_input = tokenizer_input.texts_to_sequences(df['article'])\n",
    "# padded_sequences_input = pad_sequences(sequences_input, padding='post')\n",
    "\n",
    "# tokenizer_output = Tokenizer()\n",
    "# tokenizer_output.fit_on_texts(df['highlights'])\n",
    "# sequences_output = tokenizer_output.texts_to_sequences(df['highlights'])\n",
    "# padded_sequences_output = pad_sequences(sequences_output, padding='post',maxlen = padded_sequences_input.shape[1])\n",
    "# with open('sequences.pkl', 'wb') as file:\n",
    "#     pickle.dump([padded_sequences_input,padded_sequences_output,tokenizer_input,tokenizer_output], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sequences.pkl', 'rb') as file:\n",
    "    sequences = pickle.load(file)\n",
    "\n",
    "padded_sequences_input = sequences[0]\n",
    "padded_sequences_output = sequences[1]\n",
    "tokenizer_input = sequences[2]\n",
    "tokenizer_output = sequences[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_vocab = len(tokenizer_input.word_index)\n",
    "decoder_vocab = len(tokenizer_output.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300481, 2137), (300481, 2137))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences_input.shape,padded_sequences_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                   </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">          Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ transformer_input_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>)              │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                   │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ transformer_input_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>)              │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                   │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ embedding_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">71,751,600</span> │ transformer_input_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ embedding_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">260,850,900</span> │ transformer_input_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ masked_attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,609,900</span> │ embedding_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ masked_attention_input    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                   │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ masked_attention          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,609,300</span> │ -                          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)           │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ masked_attention_add      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                          │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ -                          │\n",
       "│ masked_attention_layer_norm    │                           │                  │                            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)           │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">4,211,800</span> │ embedding_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ encoder_input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                   │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,609,900</span> │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ encoder_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                   │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ encoder_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,609,300</span> │ -                          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)           │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ encoder_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ encoder_layer_norm     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ -                          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)           │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ feed_forward (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">601,900</span> │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ feed_forward_input     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                   │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ ff_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">301,000</span> │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ ff_dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">300,300</span> │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ ff_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ ff_batch_norm          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ -                          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)           │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ transformer_attention          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,609,300</span> │ encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)           │                           │                  │ masked_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                                │                           │                  │ encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ transformer_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ masked_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                                │                           │                  │ transformer_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ transformer_layer_norm         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ transformer_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)           │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ feed_forward (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">601,900</span> │ transformer_layer_norm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ feed_forward_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                   │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ ff_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">301,000</span> │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ ff_dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">300,300</span> │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ ff_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ ff_batch_norm             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ -                          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)           │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │ feed_forward[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ output_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ output_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ output_softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "└────────────────────────────────┴───────────────────────────┴──────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m         Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ transformer_input_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m)              │                \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                   │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ transformer_input_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m)              │                \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                   │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ embedding_output (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │       \u001b[38;5;34m71,751,600\u001b[0m │ transformer_input_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ embedding_input (\u001b[38;5;33mEmbedding\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │      \u001b[38;5;34m260,850,900\u001b[0m │ transformer_input_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ masked_attention (\u001b[38;5;33mFunctional\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │        \u001b[38;5;34m3,609,900\u001b[0m │ embedding_output[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ masked_attention_input    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │                \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                   │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ masked_attention          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │        \u001b[38;5;34m3,609,300\u001b[0m │ -                          │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)           │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ masked_attention_add      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │                \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)                          │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │              \u001b[38;5;34m600\u001b[0m │ -                          │\n",
       "│ masked_attention_layer_norm    │                           │                  │                            │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)           │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │        \u001b[38;5;34m4,211,800\u001b[0m │ embedding_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ encoder_input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │                \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                   │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ encoder (\u001b[38;5;33mFunctional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │        \u001b[38;5;34m3,609,900\u001b[0m │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ encoder_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │                \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                   │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ encoder_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │        \u001b[38;5;34m3,609,300\u001b[0m │ -                          │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)           │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ encoder_add (\u001b[38;5;33mAdd\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │                \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ encoder_layer_norm     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │              \u001b[38;5;34m600\u001b[0m │ -                          │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)           │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ feed_forward (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │          \u001b[38;5;34m601,900\u001b[0m │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ feed_forward_input     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │                \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                   │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ ff_dense1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m1000\u001b[0m)        │          \u001b[38;5;34m301,000\u001b[0m │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ ff_dense2 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │          \u001b[38;5;34m300,300\u001b[0m │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ ff_add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │                \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│       └ ff_batch_norm          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │              \u001b[38;5;34m600\u001b[0m │ -                          │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)           │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ transformer_attention          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │        \u001b[38;5;34m3,609,300\u001b[0m │ encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)           │                           │                  │ masked_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                                │                           │                  │ encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ transformer_add (\u001b[38;5;33mAdd\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │                \u001b[38;5;34m0\u001b[0m │ masked_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                                │                           │                  │ transformer_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ transformer_layer_norm         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │              \u001b[38;5;34m600\u001b[0m │ transformer_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)           │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ feed_forward (\u001b[38;5;33mFunctional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │          \u001b[38;5;34m601,900\u001b[0m │ transformer_layer_norm[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ feed_forward_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │                \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                   │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ ff_dense1 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m1000\u001b[0m)        │          \u001b[38;5;34m301,000\u001b[0m │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ ff_dense2 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │          \u001b[38;5;34m300,300\u001b[0m │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ ff_add (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │                \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ ff_batch_norm             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │              \u001b[38;5;34m600\u001b[0m │ -                          │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)           │                           │                  │                            │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│ output_layer (\u001b[38;5;33mFunctional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │           \u001b[38;5;34m90,300\u001b[0m │ feed_forward[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ output_input (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │                \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ output_dense (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │           \u001b[38;5;34m90,300\u001b[0m │ -                          │\n",
       "├────────────────────────────────┼───────────────────────────┼──────────────────┼────────────────────────────┤\n",
       "│    └ output_softmax (\u001b[38;5;33mSoftmax\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2137\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │                \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "└────────────────────────────────┴───────────────────────────┴──────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">344,726,300</span> (1.28 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m344,726,300\u001b[0m (1.28 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">344,726,300</span> (1.28 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m344,726,300\u001b[0m (1.28 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 2137, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "from models import Transformer\n",
    "transformer_layer = Transformer(x_shape=(2137,),y_shape=(2137,),\n",
    "                                num_heads = 10,\n",
    "                                encoder_vocab = encoder_vocab, \n",
    "                                decoder_vocab = decoder_vocab,\n",
    "                                max_len=2137)\n",
    "model = transformer_layer.transformer()\n",
    "print(model.summary(expand_nested=True,line_length = 110))\n",
    "model.compile(optimizer='adam', \n",
    "              loss=SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy'])\n",
    "model.predict([padded_sequences_input[0:2],padded_sequences_output[0:2]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 2137), (20, 2137))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences_input[0:20].shape,padded_sequences_output[0:20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pydot' has no attribute 'InvocationException'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydot\\core.py:1799\u001b[0m, in \u001b[0;36mDot.create\u001b[1;34m(self=<pydot.core.Dot object>, prog='dot', format='ps', encoding=None)\u001b[0m\n\u001b[0;32m   1798\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1799\u001b[0m     stdout_data, stderr_data, process \u001b[38;5;241m=\u001b[39m \u001b[43mcall_graphviz\u001b[49m\u001b[43m(\u001b[49m\n        prog \u001b[1;34m= 'dot'\u001b[0m\u001b[1;34m\n        \u001b[0marguments \u001b[1;34m= ['-Tps', 'C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Temp\\\\tmpcwj8be43']\u001b[0m\u001b[1;34m\n        \u001b[0mtmp_dir \u001b[1;34m= 'C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Temp'\u001b[0m\n\u001b[0;32m   1800\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1801\u001b[0m \u001b[43m        \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworking_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1803\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydot\\core.py:222\u001b[0m, in \u001b[0;36mcall_graphviz\u001b[1;34m(program='dot.exe', arguments=['-Tps', r'C:\\Users\\ahmad\\AppData\\Local\\Temp\\tmpcwj8be43'], working_dir=r'C:\\Users\\ahmad\\AppData\\Local\\Temp', **kwargs={})\u001b[0m\n\u001b[0;32m    220\u001b[0m program_with_args \u001b[38;5;241m=\u001b[39m [program] \u001b[38;5;241m+\u001b[39m arguments\n\u001b[1;32m--> 222\u001b[0m process \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\n        program_with_args \u001b[1;34m= ['dot.exe', '-Tps', 'C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Temp\\\\tmpcwj8be43']\u001b[0m\u001b[1;34m\n        \u001b[0menv \u001b[1;34m= {'PATH': 'c:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312;c:\\\\Users\\\\ahmad\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\Scripts;C:\\\\Program Files (x86)\\\\Common Files\\\\Oracle\\\\Java\\\\javapath;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Windows\\\\System32\\\\OpenSSH\\\\;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA NvDLISR;D:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\dotnet\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Scripts\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Ollama;C:\\\\Program Files (x86)\\\\Common Files\\\\Oracle\\\\Java\\\\javapath;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Windows\\\\System32\\\\OpenSSH\\\\;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA NvDLISR;D:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\dotnet\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Scripts\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Ollama', 'LD_LIBRARY_PATH': '', 'SYSTEMROOT': 'C:\\\\Windows'}\u001b[0m\u001b[1;34m\n        \u001b[0mworking_dir \u001b[1;34m= 'C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Temp'\u001b[0m\u001b[1;34m\n        \u001b[0msubprocess.PIPE \u001b[1;34m= -1\u001b[0m\u001b[1;34m\n        \u001b[0mkwargs \u001b[1;34m= {}\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogram_with_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworking_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m stdout_data, stderr_data \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate()\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self=<Popen: returncode: None args: ['dot.exe', '-Tps', 'C:\\\\Users\\\\ahmad\\\\AppDat...>, args=['dot.exe', '-Tps', r'C:\\Users\\ahmad\\AppData\\Local\\Temp\\tmpcwj8be43'], bufsize=-1, executable=None, stdin=None, stdout=-1, stderr=-1, preexec_fn=None, close_fds=True, shell=False, cwd=r'C:\\Users\\ahmad\\AppData\\Local\\Temp', env={'LD_LIBRARY_PATH': '', 'PATH': r'c:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Pyt...\\bin;C:\\Users\\ahmad\\AppData\\Local\\Programs\\Ollama', 'SYSTEMROOT': r'C:\\Windows'}, universal_newlines=None, startupinfo=None, creationflags=0, restore_signals=True, start_new_session=False, pass_fds=(), user=None, group=None, extra_groups=None, encoding=None, errors=None, text=None, umask=-1, pipesize=-1, process_group=-1)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n        args \u001b[1;34m= ['dot.exe', '-Tps', 'C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Temp\\\\tmpcwj8be43']\u001b[0m\u001b[1;34m\n        \u001b[0mself \u001b[1;34m= <Popen: returncode: None args: ['dot.exe', '-Tps', 'C:\\\\Users\\\\ahmad\\\\AppDat...>\u001b[0m\u001b[1;34m\n        \u001b[0mpreexec_fn \u001b[1;34m= None\u001b[0m\u001b[1;34m\n        \u001b[0mclose_fds \u001b[1;34m= True\u001b[0m\u001b[1;34m\n        \u001b[0mexecutable \u001b[1;34m= None\u001b[0m\u001b[1;34m\n        \u001b[0mpass_fds \u001b[1;34m= ()\u001b[0m\u001b[1;34m\n        \u001b[0mcwd \u001b[1;34m= 'C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Temp'\u001b[0m\u001b[1;34m\n        \u001b[0menv \u001b[1;34m= {'PATH': 'c:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312;c:\\\\Users\\\\ahmad\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\Scripts;C:\\\\Program Files (x86)\\\\Common Files\\\\Oracle\\\\Java\\\\javapath;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Windows\\\\System32\\\\OpenSSH\\\\;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA NvDLISR;D:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\dotnet\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Scripts\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Ollama;C:\\\\Program Files (x86)\\\\Common Files\\\\Oracle\\\\Java\\\\javapath;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Windows\\\\System32\\\\OpenSSH\\\\;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA NvDLISR;D:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\dotnet\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Scripts\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Ollama', 'LD_LIBRARY_PATH': '', 'SYSTEMROOT': 'C:\\\\Windows'}\u001b[0m\u001b[1;34m\n        \u001b[0mstartupinfo \u001b[1;34m= None\u001b[0m\u001b[1;34m\n        \u001b[0mcreationflags \u001b[1;34m= 0\u001b[0m\u001b[1;34m\n        \u001b[0mshell \u001b[1;34m= False\u001b[0m\u001b[1;34m\n        \u001b[0mp2cread \u001b[1;34m= Handle(968)\u001b[0m\u001b[1;34m\n        \u001b[0mp2cwrite \u001b[1;34m= -1\u001b[0m\u001b[1;34m\n        \u001b[0mc2pread \u001b[1;34m= 3\u001b[0m\u001b[1;34m\n        \u001b[0mc2pwrite \u001b[1;34m= Handle(3384)\u001b[0m\u001b[1;34m\n        \u001b[0merrread \u001b[1;34m= 4\u001b[0m\u001b[1;34m\n        \u001b[0merrwrite \u001b[1;34m= Handle(3556)\u001b[0m\u001b[1;34m\n        \u001b[0mrestore_signals \u001b[1;34m= True\u001b[0m\u001b[1;34m\n        \u001b[0mgid \u001b[1;34m= None\u001b[0m\u001b[1;34m\n        \u001b[0mgids \u001b[1;34m= None\u001b[0m\u001b[1;34m\n        \u001b[0muid \u001b[1;34m= None\u001b[0m\u001b[1;34m\n        \u001b[0mumask \u001b[1;34m= -1\u001b[0m\u001b[1;34m\n        \u001b[0mprocess_group \u001b[1;34m= -1\u001b[0m\u001b[1;34m\n        \u001b[0mstart_new_session \u001b[1;34m= False\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self=<Popen: returncode: None args: ['dot.exe', '-Tps', 'C:\\\\Users\\\\ahmad\\\\AppDat...>, args=r'dot.exe -Tps C:\\Users\\ahmad\\AppData\\Local\\Temp\\tmpcwj8be43', executable=None, preexec_fn=None, close_fds=False, pass_fds=(), cwd=r'C:\\Users\\ahmad\\AppData\\Local\\Temp', env={'LD_LIBRARY_PATH': '', 'PATH': r'c:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Pyt...\\bin;C:\\Users\\ahmad\\AppData\\Local\\Programs\\Ollama', 'SYSTEMROOT': r'C:\\Windows'}, startupinfo=<subprocess.STARTUPINFO object>, creationflags=0, shell=False, p2cread=Handle(968), p2cwrite=-1, c2pread=3, c2pwrite=Handle(3384), errread=4, errwrite=Handle(3556), unused_restore_signals=True, unused_gid=None, unused_gids=None, unused_uid=None, unused_umask=-1, unused_start_new_session=False, unused_process_group=-1)\u001b[0m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n        args \u001b[1;34m= 'dot.exe -Tps C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Temp\\\\tmpcwj8be43'\u001b[0m\u001b[1;34m\n        \u001b[0mexecutable \u001b[1;34m= None\u001b[0m\u001b[1;34m\n        \u001b[0mclose_fds \u001b[1;34m= False\u001b[0m\u001b[1;34m\n        \u001b[0mnot close_fds \u001b[1;34m= True\u001b[0m\u001b[1;34m\n        \u001b[0mint(not close_fds) \u001b[1;34m= 1\u001b[0m\u001b[1;34m\n        \u001b[0mcreationflags \u001b[1;34m= 0\u001b[0m\u001b[1;34m\n        \u001b[0menv \u001b[1;34m= {'PATH': 'c:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312;c:\\\\Users\\\\ahmad\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\Scripts;C:\\\\Program Files (x86)\\\\Common Files\\\\Oracle\\\\Java\\\\javapath;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Windows\\\\System32\\\\OpenSSH\\\\;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA NvDLISR;D:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\dotnet\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Scripts\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Ollama;C:\\\\Program Files (x86)\\\\Common Files\\\\Oracle\\\\Java\\\\javapath;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Windows\\\\System32\\\\OpenSSH\\\\;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA NvDLISR;D:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\dotnet\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Scripts\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Programs\\\\Ollama', 'LD_LIBRARY_PATH': '', 'SYSTEMROOT': 'C:\\\\Windows'}\u001b[0m\u001b[1;34m\n        \u001b[0mcwd \u001b[1;34m= 'C:\\\\Users\\\\ahmad\\\\AppData\\\\Local\\\\Temp'\u001b[0m\u001b[1;34m\n        \u001b[0mstartupinfo \u001b[1;34m= <subprocess.STARTUPINFO object at 0x000001F37563C680>\u001b[0m\n\u001b[0;32m   1539\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1540\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\model_visualization.py:37\u001b[0m, in \u001b[0;36mcheck_graphviz\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# Attempt to create an image of a blank graph\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# to check the pydot/graphviz installation.\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydot\\core.py:1808\u001b[0m, in \u001b[0;36mDot.create\u001b[1;34m(self=<pydot.core.Dot object>, prog='dot', format='ps', encoding=None)\u001b[0m\n\u001b[0;32m   1807\u001b[0m     args[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprog\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not found in path.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1808\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;241m*\u001b[39margs)\n        args \u001b[1;34m= [2, '\"dot\" not found in path.', None, 2, None]\u001b[0m\n\u001b[0;32m   1809\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_plot.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_layer_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n        model \u001b[1;34m= <Functional name=transformer_model, built=True>\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\model_visualization.py:430\u001b[0m, in \u001b[0;36mplot_model\u001b[1;34m(model=<Functional name=transformer_model, built=True>, to_file='model_plot.png', show_shapes=True, show_dtype=False, show_layer_names=True, rankdir='TB', expand_nested=False, dpi=200, show_layer_activations=False, show_trainable=False, **kwargs={})\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(message)\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcheck_graphviz\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    431\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must install graphviz \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    433\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(see instructions at https://graphviz.gitlab.io/download/) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor `plot_model` to work.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m     )\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython.core.magics.namespace\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;66;03m# We don't raise an exception here in order to avoid crashing\u001b[39;00m\n\u001b[0;32m    438\u001b[0m         \u001b[38;5;66;03m# notebook tests where graphviz is not available.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ahmad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\model_visualization.py:39\u001b[0m, in \u001b[0;36mcheck_graphviz\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m     pydot\u001b[38;5;241m.\u001b[39mDot\u001b[38;5;241m.\u001b[39mcreate(pydot\u001b[38;5;241m.\u001b[39mDot())\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInvocationException\u001b[49m):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pydot' has no attribute 'InvocationException'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300481, 2137)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300481, 2137)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
